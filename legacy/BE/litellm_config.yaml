model_list:
  - model_name: gemini-flash
    litellm_params:
      model: gemini/gemini-1.5-flash-latest
      api_key: os.environ/GEMINI_API_KEY
      rpm: 50

  - model_name: gpt-4o-mini
    litellm_params:
      model: openai/gpt-4o-mini
      api_key: os.environ/OPENAI_API_KEY
      rpm: 50

litellm_settings:
  drop_params: False
  set_verbose: False
  cache: False          # set cache responses to True, litellm defaults to using a redis cache
