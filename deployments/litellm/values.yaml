# Default values for litellm.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  # Use "ghcr.io/berriai/litellm-database" for optimized image with database
  repository: ghcr.io/berriai/litellm-database
  pullPolicy: Always
  # Overrides the image tag whose default is the chart appVersion.
  # tag: "main-latest"
  tag: "main-v1.44.6-stable"

  # Image and tag used for the init container to check and wait for the
  #  readiness of the postgres database.
  dbReadyImage: docker.io/bitnami/postgresql
  dbReadyTag: ""

imagePullSecrets: []
nameOverride: "litellm"
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: false
  # Automatically mount a ServiceAccount's API credentials?
  automount: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

podAnnotations: {}
podLabels: {}

# At the time of writing, the litellm docker image requires write access to the
#  filesystem on startup so that prisma can install some dependencies.
podSecurityContext: {}
securityContext: {}
  # capabilities:
  #   drop:
  #     - ALL
  # readOnlyRootFilesystem: false
  # runAsNonRoot: true
  # runAsUser: 1000

# A list of Kubernetes Secret objects that will be exported to the LiteLLM proxy
#  pod as environment variables.  These secrets can then be referenced in the
#  configuration file (or "litellm" ConfigMap) with `os.environ/<Env Var Name>`
environmentSecrets:
  - easyllmops-env

service:
  type: ClusterIP
  port: 4000

ingress:
  enabled: false
  className: "nginx"
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: api.example.local
      paths:
        - path: /
          pathType: ImplementationSpecific
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

# masterkey: changeit

# The elements within proxy_config are rendered as config.yaml for the proxy
#  Examples: https://github.com/BerriAI/litellm/tree/main/litellm/proxy/example_config_yaml
#  Reference: https://docs.litellm.ai/docs/proxy/configs
proxy_config:
  model_list:
    - model_name: Gemini Flash
      litellm_params:
        model: gemini/gemini-1.5-flash
        api_key: os.environ/GEMINI_API_KEY
        rpm: 50

    # - model_name: Gemini Pro
    #   litellm_params:
    #     model: gemini/gemini-1.5-pro
    #     api_key: os.environ/GEMINI_API_KEY
    #     rpm: 10

    - model_name: Llama-3.1-8b # llama-3.1-70b-versatile
      litellm_params:
        model: groq/llama-3.1-8b-instant
        api_key: os.environ/GROQ_API_KEY
        rpm: 30

    - model_name: Llama-3.1-70b
      litellm_params:
        model: groq/llama-3.1-8b-instant
        api_key: os.environ/GROQ_API_KEY
        rpm: 30

    - model_name: GPT-4o mini
      litellm_params:
        model: openai/gpt-4o-mini
        api_key: os.environ/OPENAI_API_KEY
        rpm: 0

  litellm_settings:
    num_retries: 3
    request_timeout: 15 # raise Timeout error if call takes longer than 15s. Sets litellm.request_timeout
    fallbacks: [
      {"Llama-3.1-8b": ["Gemini Flash"]},
      {"Llama-3.1-70b": ["Gemini Flash"]},
      {"GPT-4o mini": ["Gemini Flash"]},
    ]
    allowed_fails: 3 # cooldown model if it fails > 1 call in a minute. 
    cooldown_time: 30 # how long to cooldown model if fails/min > allowed_fails
    success_callback: ["langfuse", "supabase"]
    failure_callback: ["langfuse", "supabase"]
    drop_params: true
    set_verbose: false
    cache: true
    # cache_params:
    #   type: "redis-semantic"  
    #   similarity_threshold: 0.8   # similarity threshold for semantic cache
    #   redis_semantic_cache_embedding_model: gemini-embedding # set this to a model_name set in model_list

  router_settings:
    routing_strategy: simple-shuffle # Literal["simple-shuffle", "least-busy", "usage-based-routing","latency-based-routing"], default="simple-shuffle"
    model_group_alias: {"GPT-4o mini": "Gemini Flash"} # all requests with `gpt-4` will be routed to models with `gpt-3.5-turbo`
    num_retries: 2
    timeout: 30        
    redis_host: os.environ/REDIS_HOST
    redis_password: os.environ/REDIS_PASSWORD
    redis_port: os.environ/REDIS_PORT

  # environment_variables:
  #   SUPABASE_URL: os.environ/SUPABASE_URL
  #   SUPABASE_KEY: os.environ/SUPABASE_KEY
  #   redis_host: os.environ/REDIS_HOST
  #   redis_password: os.environ/REDIS_PASSWORD
  #   redis_port: os.environ/REDIS_PORT

resources:
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  requests:
    cpu: 200m
    memory: 256Mi
  limits:
    cpu: 1000m
    memory: 1Gi

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80

# Additional volumes on the output Deployment definition.
volumes: []
# - name: foo
#   secret:
#     secretName: mysecret
#     optional: false

# Additional volumeMounts on the output Deployment definition.
volumeMounts: []
# - name: foo
#   mountPath: "/etc/foo"
#   readOnly: true

nodeSelector: {}

tolerations: []

affinity: {}

db:
  # Use an existing postgres server/cluster
  useExisting: false

  # How to connect to the existing postgres server/cluster
  endpoint: localhost
  database: litellm
  secret:
    name: postgres
    usernameKey: username
    passwordKey: password

  # Use the Stackgres Helm chart to deploy an instance of a Stackgres cluster.
  #  The Stackgres Operator must already be installed within the target
  #  Kubernetes cluster.
  # TODO: Stackgres deployment currently unsupported
  useStackgresOperator: false

  # Use the Postgres Helm chart to create a single node, stand alone postgres
  #  instance.  See the "postgresql" top level key for additional configuration.
  deployStandalone: true

# Settings for Bitnami postgresql chart (if db.deployStandalone is true, ignored
#  otherwise)
postgresql:
  architecture: standalone
  auth:
    username: litellm
    database: litellm

    # You should override these on the helm command line with
    #  `--set postgresql.auth.postgres-password=<some good password>,postgresql.auth.password=<some good password>`
    password: NoTaGrEaTpAsSwOrD
    postgres-password: NoTaGrEaTpAsSwOrD

    # A secret is created by this chart (litellm-helm) with the credentials that
    #  the new Postgres instance should use.
    # existingSecret: ""
    # secretKeys:
    #   userPasswordKey: password

# requires cache: true in config file
# either enable this or pass a secret for REDIS_HOST, REDIS_PORT, REDIS_PASSWORD or REDIS_URL
# with cache: true to use existing redis instance
redis:
  enabled: false
  architecture: standalone
